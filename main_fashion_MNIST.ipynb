{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from my_model import forward_prop, backward_prop, forward_prop_multi, backward_prop_multi\n",
    "from opti_base import init_params, update_params_gd\n",
    "from opti_mini import random_mini_batches\n",
    "from opti_mome import init_mome, update_params_mome\n",
    "from opti_RMSprop import init_rmsp, update_params_rmsp\n",
    "from opti_adam import init_adam, update_params_adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = f_mnist.load_data()\n",
    "\n",
    "# images : 28*28 (0~255), labels : 1 (0~9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 0\n",
    "\n",
    "plt.imshow(train_images[ind], cmap = 'gray')\n",
    "plt.title(\"Label : \" + str(train_labels[ind]), fontsize = 15)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train X : (60000, 28, 28)\n",
      "Shape of train y : (60000,)\n",
      "Shape of test X : (10000, 28, 28)\n",
      "Shape of test y : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train X :\", train_images.shape)\n",
    "print(\"Shape of train y :\", train_labels.shape)\n",
    "print(\"Shape of test X :\", test_images.shape)\n",
    "print(\"Shape of test y :\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x train: (784, 60000)\n",
      "Shape of y train: (10, 60000)\n",
      "Shape of x test: (784, 10000)\n",
      "Shape of y test: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "x_train_flatten = train_images.reshape(train_images.shape[0], -1).T\n",
    "x_test_flatten = test_images.reshape(test_images.shape[0], -1).T\n",
    "\n",
    "# Normalize image vectors\n",
    "x_train = x_train_flatten/255.\n",
    "x_test = x_test_flatten/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "enc = OneHotEncoder()\n",
    "y1 = train_labels.reshape(-1,1)\n",
    "enc.fit(y1)\n",
    "y_train = enc.transform(y1).toarray()\n",
    "y_train = y_train.T\n",
    "\n",
    "y2 = test_labels.reshape(-1,1)\n",
    "enc.fit(y2)\n",
    "y_test = enc.transform(y2).toarray()\n",
    "y_test = y_test.T\n",
    "\n",
    "# Explore dataset \n",
    "print (\"Shape of x train: \" + str(x_train.shape))\n",
    "print (\"Shape of y train: \" + str(y_train.shape))\n",
    "print (\"Shape of x test: \" + str(x_test.shape))\n",
    "print (\"Shape of y test: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 1000, print_cost = True):\n",
    "    \n",
    "    # 3-layer neural network\n",
    "    \n",
    "    L = len(layers_dims)            \n",
    "    costs = []                      \n",
    "    t = 0     # counter                  \n",
    "    seed = 10                    \n",
    "    m = X.shape[1]          \n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = init_params(layers_dims, Y.shape[0])\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass   # no initialization required\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = init_mome(parameters)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        s = init_rmsp(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = init_adam(parameters)\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        seed = seed + 1 # reshuffle differently the dataset after each epoch\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward prop\n",
    "            a3, caches = forward_prop_multi(minibatch_X, parameters)\n",
    "            logprobs = np.multiply(-np.log(a3),minibatch_Y)\n",
    "            cost_total += np.sum(logprobs)\n",
    "\n",
    "            # Backward prop\n",
    "            grads = backward_prop_multi(minibatch_X, minibatch_Y, caches)\n",
    "\n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_params_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_params_mome(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == 'rmsprop':\n",
    "                parameters, s = update_params_rmsp(parameters, grads, s, beta, learning_rate, epsilon)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # counter\n",
    "                parameters, v, s = update_params_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost_avg = cost_total / m\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
    "        if print_cost and i % 10 == 0:\n",
    "            costs.append(cost_avg)\n",
    "                \n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m), dtype = np.int)\n",
    "    \n",
    "    a3, caches = forward_prop(X, parameters)\n",
    "    \n",
    "    p = A.argmax(axis=0)  # prediction\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.mean((p == y))))\n",
    "    \n",
    "    return p, a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mini-batch Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-53c52c35a1c3>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, layers_dims, optimizer, learning_rate, mini_batch_size, beta, beta1, beta2, epsilon, num_epochs, print_cost)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gd\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_gd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"momentum\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_mome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Desktop\\Github\\ML_Optimization_Methods\\opti_base.py\u001b[0m in \u001b[0;36mupdate_params_gd\u001b[1;34m(parameters, grads, learning_rate)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers_dims = [x_train.shape[0], 1024, 784, 10]\n",
    "parameters = model(x_train, y_train, layers_dims, optimizer = \"gd\")\n",
    "\n",
    "predictions_gd, prob_gd = predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-06b9a78187b2>:36: RuntimeWarning: divide by zero encountered in log\n",
      "  logprobs = np.multiply(-np.log(a3),minibatch_Y)\n",
      "<ipython-input-26-06b9a78187b2>:36: RuntimeWarning: invalid value encountered in multiply\n",
      "  logprobs = np.multiply(-np.log(a3),minibatch_Y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-06b9a78187b2>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, layers_dims, optimizer, learning_rate, mini_batch_size, beta, beta1, beta2, epsilon, num_epochs, print_cost)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_gd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"momentum\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_mome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_rmsp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Desktop\\Github\\ML_Optimization_Methods\\opti_mome.py\u001b[0m in \u001b[0;36mupdate_params_mome\u001b[1;34m(parameters, grads, v, beta, learning_rate)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# velocities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dW\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dW\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers_dims = [x_train.shape[0], 1024, 784, 10]\n",
    "parameters = model(x_train, y_train, layers_dims, optimizer = \"momentum\")\n",
    "\n",
    "predictions_gd, prob_gd = predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-06b9a78187b2>:36: RuntimeWarning: divide by zero encountered in log\n",
      "  logprobs = np.multiply(-np.log(a3),minibatch_Y)\n",
      "<ipython-input-26-06b9a78187b2>:36: RuntimeWarning: invalid value encountered in multiply\n",
      "  logprobs = np.multiply(-np.log(a3),minibatch_Y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-06b9a78187b2>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, layers_dims, optimizer, learning_rate, mini_batch_size, beta, beta1, beta2, epsilon, num_epochs, print_cost)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_mome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_rmsp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# counter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Desktop\\Github\\ML_Optimization_Methods\\opti_RMSprop.py\u001b[0m in \u001b[0;36mupdate_params_rmsp\u001b[1;34m(parameters, grads, s, learning_rate, beta, epsilon)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Moving average of the squared gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dW\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dW\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers_dims = [x_train.shape[0], 1024, 784, 10]\n",
    "parameters = model(x_train, y_train, layers_dims, beta = 0.999, learning_rate = 0.007, optimizer = \"rmsprop\")\n",
    "\n",
    "# Predict\n",
    "predictions_gd, prob_adam = predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers_dims = [x_train.shape[0], 1024, 784, 10]\n",
    "parameters = model(x_train, y_train, layers_dims, optimizer = \"adam\")\n",
    "\n",
    "# Predict\n",
    "predictions_gd, prob_adam = predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Deep Learning Specialization on Coursera, https://www.coursera.org/specializations/deep-learning  \n",
    "[2] Kingma, Diederik P., and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014)."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "Ckiv2",
   "launcher_item_id": "eNLYh"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
